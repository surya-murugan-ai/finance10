import type { Express } from "express";
import express from "express";
import { createServer, type Server } from "http";
import multer from "multer";
import { storage } from "./storage";
import { setupAuth, isAuthenticated } from "./replitAuth";
import { fileProcessorService } from "./services/fileProcessor";
import { langGraphOrchestrator } from "./services/langGraph";
import { complianceCheckerService } from "./services/complianceChecker";
import { financialReportsService } from "./services/financialReports";
import { dataSourceService } from "./services/dataSourceService";
import { insertDocumentSchema } from "@shared/schema";
import { nanoid } from "nanoid";
import { writeFile } from "fs/promises";
import path from "path";

// Helper function to format currency numbers as text
function formatCurrency(amount: number): string {
  if (amount === 0) return 'Rs 0';
  return `Rs ${amount.toLocaleString('en-IN')}`;
}

// JWT middleware for API endpoints
const jwtAuth = (req: any, res: any, next: any) => {
  try {
    const authHeader = req.headers.authorization;
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({ message: 'Unauthorized' });
    }
    
    const token = authHeader.split(' ')[1];
    
    try {
      const decoded = JSON.parse(Buffer.from(token, 'base64').toString());
      req.user = {
        claims: {
          sub: decoded.userId
        },
        userId: decoded.userId,
        email: decoded.email
      };
      next();
    } catch (decodeError) {
      return res.status(401).json({ message: 'Unauthorized' });
    }
  } catch (error) {
    return res.status(401).json({ message: 'Unauthorized' });
  }
};

// Helper functions for dashboard stats
function getCurrentQuarter(): string {
  const now = new Date();
  const month = now.getMonth();
  const year = now.getFullYear();
  
  if (month < 3) return `Q4_${year - 1}`;
  if (month < 6) return `Q1_${year}`;
  if (month < 9) return `Q2_${year}`;
  return `Q3_${year}`;
}

function getNextDueDate(): string {
  const now = new Date();
  const nextMonth = new Date(now.getFullYear(), now.getMonth() + 1, 15);
  return nextMonth.toISOString().split('T')[0];
}

// Helper function for basic anomaly detection (fallback)
async function performBasicAnomalyDetection(transactions: any[], document: any): Promise<any[]> {
  const anomalies: any[] = [];
  
  if (transactions.length === 0) return anomalies;
  
  // Calculate basic statistics
  const amounts = transactions.map(t => Math.abs(t.debitAmount || t.creditAmount || 0));
  const mean = amounts.reduce((a, b) => a + b, 0) / amounts.length;
  const variance = amounts.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / amounts.length;
  const stdDev = Math.sqrt(variance);
  
  // Flag outliers (amounts > 2 standard deviations from mean)
  transactions.forEach(transaction => {
    const amount = Math.abs(transaction.debitAmount || transaction.creditAmount || 0);
    if (amount > mean + 2 * stdDev) {
      anomalies.push({
        id: `anomaly_${transaction.id}`,
        transactionId: transaction.id,
        documentId: document.id,
        anomalyScore: 75,
        confidence: 0.8,
        anomalyType: 'amount_anomaly',
        severity: 'MEDIUM',
        reasoning: `Transaction amount ${amount} is significantly higher than average (${mean.toFixed(2)})`,
        evidence: [`Amount: ${amount}`, `Mean: ${mean.toFixed(2)}`, `Std Dev: ${stdDev.toFixed(2)}`],
        recommendations: ['Review transaction for accuracy', 'Verify supporting documentation'],
        businessContext: 'Statistical outlier detection',
        riskFactors: ['Unusual amount'],
        suggestedActions: [],
        followUpQuestions: ['Is this amount correct?', 'Is there proper authorization?'],
        relatedTransactions: []
      });
    }
  });
  
  return anomalies;
}

// Helper function to infer document type from filename
function inferDocumentType(fileName: string): string {
  const name = fileName.toLowerCase();
  if (name.includes('vendor') || name.includes('invoice')) return 'vendor_invoice';
  if (name.includes('sales') || name.includes('register')) return 'sales_register';
  if (name.includes('salary') || name.includes('payroll')) return 'salary_register';
  if (name.includes('bank') || name.includes('statement')) return 'bank_statement';
  if (name.includes('purchase') || name.includes('procurement')) return 'purchase_register';
  return 'vendor_invoice'; // default
}

// Helper function to generate sample data for documents
function generateSampleDataForDocument(docType: string, fileName: string) {
  // Generate more realistic sample data based on actual document names
  const baseData = {
    vendor_invoice: {
      invoices: [
        {
          invoiceNumber: fileName.includes('test') ? "TEST-VI-2025-001" : "VI-2025-001",
          vendorName: fileName.includes('abc') ? "ABC Corp" : fileName.includes('tech') ? "TechCorp Solutions" : "Vendor Corp Ltd",
          invoiceDate: "2025-01-15",
          amount: Math.floor(Math.random() * 500000) + 50000,
          gstin: "09ABCDE1234F1Z5",
          status: Math.random() > 0.5 ? "paid" : "pending"
        },
        {
          invoiceNumber: fileName.includes('test') ? "TEST-VI-2025-002" : "VI-2025-002",
          vendorName: fileName.includes('supplies') ? "Office Supplies Ltd" : "Global Vendor Inc",
          invoiceDate: "2025-01-20",
          amount: Math.floor(Math.random() * 200000) + 25000,
          gstin: "09DEFGH5678K2Y6",
          status: Math.random() > 0.5 ? "paid" : "pending"
        }
      ]
    },
    sales_register: {
      sales: [
        {
          invoiceNumber: fileName.includes('test') ? "TEST-SR-2025-001" : "SR-2025-001",
          customerName: fileName.includes('global') ? "Global Enterprises" : "Enterprise Customer Ltd",
          saleDate: "2025-01-10",
          taxableAmount: Math.floor(Math.random() * 300000) + 100000,
          gstAmount: Math.floor(Math.random() * 54000) + 18000,
          totalAmount: Math.floor(Math.random() * 354000) + 118000
        },
        {
          invoiceNumber: fileName.includes('test') ? "TEST-SR-2025-002" : "SR-2025-002",
          customerName: fileName.includes('regional') ? "Regional Corp" : "Corporate Solutions Inc",
          saleDate: "2025-01-12",
          taxableAmount: Math.floor(Math.random() * 200000) + 75000,
          gstAmount: Math.floor(Math.random() * 36000) + 13500,
          totalAmount: Math.floor(Math.random() * 236000) + 88500
        }
      ]
    },
    salary_register: {
      employees: [
        {
          employeeId: fileName.includes('test') ? "TEST-EMP001" : "EMP001",
          employeeName: fileName.includes('john') ? "John Doe" : "Employee One",
          department: fileName.includes('finance') ? "Finance" : "General",
          basicSalary: Math.floor(Math.random() * 50000) + 50000,
          tdsDeducted: Math.floor(Math.random() * 10000) + 5000,
          netSalary: Math.floor(Math.random() * 45000) + 45000
        },
        {
          employeeId: fileName.includes('test') ? "TEST-EMP002" : "EMP002",
          employeeName: fileName.includes('jane') ? "Jane Smith" : "Employee Two",
          department: fileName.includes('operations') ? "Operations" : "Support",
          basicSalary: Math.floor(Math.random() * 60000) + 60000,
          tdsDeducted: Math.floor(Math.random() * 12000) + 6000,
          netSalary: Math.floor(Math.random() * 54000) + 54000
        }
      ]
    },
    bank_statement: {
      transactions: [
        {
          date: "2025-01-15",
          description: fileName.includes('test') ? "Test Transaction - Customer Payment" : "Customer Payment - Global Enterprises",
          reference: "UPI/" + Math.floor(Math.random() * 1000000000),
          debit: 0,
          credit: Math.floor(Math.random() * 500000) + 100000,
          balance: Math.floor(Math.random() * 2000000) + 1000000
        },
        {
          date: "2025-01-16",
          description: fileName.includes('test') ? "Test Transaction - Vendor Payment" : "Vendor Payment - TechCorp Solutions",
          reference: "NEFT/" + Math.floor(Math.random() * 1000000000),
          debit: Math.floor(Math.random() * 300000) + 50000,
          credit: 0,
          balance: Math.floor(Math.random() * 1500000) + 500000
        }
      ]
    },
    purchase_register: {
      purchases: [
        {
          purchaseOrder: fileName.includes('test') ? "TEST-PO-2025-001" : "PO-2025-001",
          vendorName: fileName.includes('raw') ? "Raw Materials Inc" : "Purchase Vendor Corp",
          purchaseDate: "2025-01-14",
          itemDescription: fileName.includes('steel') ? "Steel Sheets - Grade A" : "Office Equipment",
          quantity: Math.floor(Math.random() * 200) + 50,
          amount: Math.floor(Math.random() * 1000000) + 200000
        },
        {
          purchaseOrder: fileName.includes('test') ? "TEST-PO-2025-002" : "PO-2025-002",
          vendorName: fileName.includes('equipment') ? "Equipment Suppliers" : "Supply Chain Partners",
          purchaseDate: "2025-01-18",
          itemDescription: fileName.includes('machinery') ? "Industrial Machinery" : "Business Supplies",
          quantity: Math.floor(Math.random() * 10) + 1,
          amount: Math.floor(Math.random() * 1500000) + 300000
        }
      ]
    }
  };

  return (baseData as any)[docType] || {};
}

// Configure multer for file uploads
const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 100 * 1024 * 1024, // 100MB
  },
});

export async function registerRoutes(app: Express): Promise<Server> {
  // Ensure JSON middleware is set up
  app.use(express.json());
  app.use(express.urlencoded({ extended: true }));
  
  // Auth middleware
  await setupAuth(app);
  
  // Simple authentication endpoints for testing
  app.post('/api/auth/login', async (req, res) => {
    try {
      const { email, password } = req.body;
      
      console.log('Login attempt with email:', email, 'password:', password);
      
      // For demo purposes, accept the test user credentials or any registered user
      if (email === 'testuser@example.com' && password === 'TestPassword123!') {
        const user = {
          id: '9e36c4db-56c4-4175-9962-7d103db2c1cd',
          email: 'testuser@example.com',
          first_name: 'Test',
          last_name: 'User',
          company_name: 'Test Company Ltd',
          is_active: true
        };
        
        // Create a simple token (in production, use proper JWT)
        const token = Buffer.from(JSON.stringify({ userId: user.id, email: user.email })).toString('base64');
        
        console.log('Login successful for:', email);
        
        res.json({
          success: true,
          access_token: token,
          user: user
        });
      } else if (email && password) {
        // For demo purposes, accept any valid email/password combination
        // In production, validate against database
        const user = {
          id: nanoid(),
          email: email,
          first_name: 'Demo',
          last_name: 'User',
          company_name: 'Demo Company',
          is_active: true
        };
        
        // Create a simple token (in production, use proper JWT)
        const token = Buffer.from(JSON.stringify({ userId: user.id, email: user.email })).toString('base64');
        
        console.log('Login successful for demo user:', email);
        
        res.json({
          success: true,
          access_token: token,
          user: user
        });
      } else {
        console.log('Login failed - invalid credentials for:', email);
        res.status(401).json({ success: false, message: 'Invalid credentials' });
      }
    } catch (error) {
      console.error('Login error:', error);
      res.status(500).json({ success: false, message: 'Internal server error' });
    }
  });

  app.post('/api/auth/register', async (req, res) => {
    console.log('Registration endpoint called with body:', req.body);
    
    try {
      const { email, password, first_name, last_name, company_name, phone } = req.body;
      
      // Basic validation
      if (!email || !password || !first_name || !last_name) {
        console.log('Registration validation failed - missing required fields');
        return res.status(400).json({ 
          success: false, 
          message: 'Email, password, first name, and last name are required' 
        });
      }
      
      // For demo purposes, create a new user (in production, save to database)
      const newUserId = nanoid();
      const user = {
        id: newUserId,
        email,
        first_name,
        last_name,
        company_name: company_name || null,
        phone: phone || null,
        is_active: true
      };
      
      // Create a simple token (in production, use proper JWT)
      const token = Buffer.from(JSON.stringify({ userId: user.id, email: user.email })).toString('base64');
      
      console.log('Registration successful for user:', email);
      
      res.json({
        success: true,
        message: 'Account created successfully',
        access_token: token,
        user: user
      });
    } catch (error) {
      console.error('Registration error:', error);
      res.status(500).json({ success: false, message: 'Internal server error' });
    }
  });
  
  app.get('/api/auth/user', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const email = req.user.claims.email;
      
      const user = {
        id: userId,
        email: email,
        first_name: 'Test',
        last_name: 'User',
        company_name: 'Test Company Ltd',
        is_active: true
      };
      
      res.json({ success: true, user: user });
    } catch (error) {
      res.status(500).json({ success: false, message: 'Internal server error' });
    }
  });
  
  app.post('/api/auth/logout', async (req, res) => {
    res.json({ success: true, message: 'Logged out successfully' });
  });

  // Remove duplicate route - already defined above

  // Onboarding API endpoints
  app.post("/api/onboarding", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const onboardingData = req.body;
      
      // Store company information
      await storage.createCompanyProfile({
        userId,
        ...onboardingData.company,
        entities: onboardingData.entities,
        users: onboardingData.users,
        calendar: onboardingData.calendar,
        createdAt: new Date(),
        updatedAt: new Date(),
      });
      
      // Track user flow
      await storage.createUserFlowEntry({
        userId,
        step: "onboarding_complete",
        action: "completed_setup",
        metadata: JSON.stringify({ entitiesCount: onboardingData.entities.length, usersCount: onboardingData.users.length }),
        timestamp: new Date(),
      });
      
      res.json({ message: "Onboarding completed successfully" });
    } catch (error) {
      console.error("Error completing onboarding:", error);
      res.status(500).json({ error: "Failed to complete onboarding" });
    }
  });

  app.get("/api/company", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const company = await storage.getCompanyProfile(userId);
      res.json(company);
    } catch (error) {
      console.error("Error fetching company:", error);
      res.status(500).json({ error: "Failed to fetch company profile" });
    }
  });

  // User flow tracking endpoints
  app.post("/api/user-flow", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const { step, action, metadata } = req.body;
      
      await storage.createUserFlowEntry({
        userId,
        step,
        action,
        metadata: JSON.stringify(metadata),
        timestamp: new Date(),
      });
      
      res.json({ message: "User flow tracked successfully" });
    } catch (error) {
      console.error("Error tracking user flow:", error);
      res.status(500).json({ error: "Failed to track user flow" });
    }
  });

  app.get("/api/user-flow", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const flows = await storage.getUserFlowEntries(userId);
      res.json(flows);
    } catch (error) {
      console.error("Error fetching user flows:", error);
      res.status(500).json({ error: "Failed to fetch user flows" });
    }
  });

  // Close calendar endpoints
  app.get("/api/close-calendar", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const calendar = await storage.getCloseCalendar(userId);
      res.json(calendar);
    } catch (error) {
      console.error("Error fetching close calendar:", error);
      res.status(500).json({ error: "Failed to fetch close calendar" });
    }
  });

  app.put("/api/close-calendar", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const calendarData = req.body;
      
      const updatedCalendar = await storage.updateCloseCalendar(userId, calendarData);
      res.json(updatedCalendar);
    } catch (error) {
      console.error("Error updating close calendar:", error);
      res.status(500).json({ error: "Failed to update close calendar" });
    }
  });

  // User roles endpoints
  app.get("/api/user-roles", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const roles = await storage.getUserRoles(userId);
      res.json(roles);
    } catch (error) {
      console.error("Error fetching user roles:", error);
      res.status(500).json({ error: "Failed to fetch user roles" });
    }
  });

  app.post("/api/user-roles", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const roleData = req.body;
      
      const role = await storage.createUserRole({
        userId,
        ...roleData,
        createdAt: new Date(),
        updatedAt: new Date(),
      });
      
      res.json(role);
    } catch (error) {
      console.error("Error creating user role:", error);
      res.status(500).json({ error: "Failed to create user role" });
    }
  });

  // Enhanced dashboard stats with user journey tracking
  app.get("/api/dashboard/stats", isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const stats = await storage.getDashboardStats(userId);
      
      // Add user journey progress
      const company = await storage.getCompanyProfile(userId);
      const onboardingComplete = !!company;
      
      const enhancedStats = {
        ...stats,
        onboardingComplete,
        currentQuarter: getCurrentQuarter(),
        nextDueDate: getNextDueDate(),
      };
      
      res.json(enhancedStats);
    } catch (error) {
      console.error("Error fetching dashboard stats:", error);
      res.status(500).json({ error: "Failed to fetch dashboard stats" });
    }
  });

  // Document upload route
  app.post('/api/documents/upload', jwtAuth, upload.single('file'), async (req: any, res) => {
    try {
      console.log("Upload request received");
      
      if (!req.file) {
        console.log("No file in request");
        return res.status(400).json({ message: "No file uploaded" });
      }

      const userId = req.user.claims.sub;
      const file = req.file;
      const fileName = `${nanoid()}_${file.originalname}`;

      console.log("File details:", {
        originalname: file.originalname,
        mimetype: file.mimetype,
        size: file.size,
        userId
      });

      // Simple extension validation only
      const allowedExtensions = ['.xlsx', '.xls', '.csv', '.pdf'];
      const fileExtension = path.extname(file.originalname).toLowerCase();
      
      if (!allowedExtensions.includes(fileExtension)) {
        return res.status(400).json({ message: `File type ${fileExtension} not supported` });
      }

      // Save file directly without complex validation
      console.log("Saving file directly");
      const filePath = path.join(process.cwd(), 'uploads', fileName);
      await writeFile(filePath, file.buffer);
      console.log("File saved to:", filePath);

      // Create document record
      console.log("Creating document record");
      const document = await storage.createDocument({
        fileName,
        originalName: file.originalname,
        mimeType: file.mimetype,
        fileSize: file.size,
        filePath: filePath,
        uploadedBy: userId,
        status: 'uploaded',
        metadata: { size: file.size, mimeType: file.mimetype },
      });
      console.log("Document created:", document.id);

      // Start LangGraph workflow (temporarily disabled for debugging)
      let workflowId = null;
      console.log("Skipping LangGraph workflow for now");
      // TODO: Re-enable workflow after fixing timeout issues
      // try {
      //   workflowId = await langGraphOrchestrator.startDocumentProcessingWorkflow(
      //     document.id,
      //     userId
      //   );
      // } catch (error) {
      //   console.error("Workflow start failed:", error);
      //   // Continue without workflow for now
      // }

      // Log audit trail
      await storage.createAuditTrail({
        action: 'document_uploaded',
        entityType: 'document',
        entityId: document.id,
        userId,
        details: {
          fileName: file.originalname,
          fileSize: file.size,
          workflowId: workflowId || 'none',
        },
      });

      res.json({
        document,
        workflowId: workflowId || 'none',
        message: "Document uploaded and saved successfully",
      });
    } catch (error) {
      console.error("Error uploading document:", error);
      res.status(500).json({ message: "Failed to upload document" });
    }
  });

  // Get documents
  app.get('/api/documents', jwtAuth, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const documents = await storage.getDocuments(userId);
      res.json(documents);
    } catch (error) {
      console.error("Error fetching documents:", error);
      res.status(500).json({ message: "Failed to fetch documents" });
    }
  });

  // Get document by ID
  app.get('/api/documents/:id', jwtAuth, async (req: any, res) => {
    try {
      const document = await storage.getDocument(req.params.id);
      if (!document) {
        return res.status(404).json({ message: "Document not found" });
      }
      res.json(document);
    } catch (error) {
      console.error("Error fetching document:", error);
      res.status(500).json({ message: "Failed to fetch document" });
    }
  });

  // Delete document
  app.delete('/api/documents/:id', jwtAuth, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const documentId = req.params.id;
      
      // Validate UUID format
      const uuidRegex = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
      if (!uuidRegex.test(documentId)) {
        return res.status(400).json({ message: "Invalid document ID format" });
      }
      
      const document = await storage.getDocument(documentId);
      
      if (!document) {
        return res.status(404).json({ message: "Document not found" });
      }

      if (document.uploadedBy !== userId) {
        return res.status(403).json({ message: "Unauthorized to delete this document" });
      }

      await storage.deleteDocument(documentId);
      await fileProcessorService.deleteFile(document.filePath);

      // Log audit trail
      await storage.createAuditTrail({
        action: 'document_deleted',
        entityType: 'document',
        entityId: documentId,
        userId,
        details: { fileName: document.originalName },
      });

      res.json({ message: "Document deleted successfully" });
    } catch (error) {
      console.error("Error deleting document:", error);
      res.status(500).json({ message: "Failed to delete document" });
    }
  });

  // Get agent jobs
  app.get('/api/agent-jobs', isAuthenticated, async (req: any, res) => {
    try {
      const documentId = req.query.documentId as string;
      const jobs = await storage.getAgentJobs(documentId);
      res.json(jobs);
    } catch (error) {
      console.error("Error fetching agent jobs:", error);
      res.status(500).json({ message: "Failed to fetch agent jobs" });
    }
  });

  // Get workflow status
  app.get('/api/workflows/:id', isAuthenticated, async (req: any, res) => {
    try {
      const workflowStatus = langGraphOrchestrator.getWorkflowStatus(req.params.id);
      if (!workflowStatus) {
        return res.status(404).json({ message: "Workflow not found" });
      }
      res.json(workflowStatus);
    } catch (error) {
      console.error("Error fetching workflow status:", error);
      res.status(500).json({ message: "Failed to fetch workflow status" });
    }
  });

  // Get active workflows
  app.get('/api/workflows', isAuthenticated, async (req: any, res) => {
    try {
      const workflows = await langGraphOrchestrator.getActiveWorkflows();
      res.json(workflows);
    } catch (error) {
      console.error("Error fetching workflows:", error);
      res.status(500).json({ message: "Failed to fetch workflows" });
    }
  });

  // Execute workflow for a specific document
  app.post('/api/workflows/execute', isAuthenticated, async (req: any, res) => {
    try {
      const { workflowId, documentId } = req.body;
      const userId = req.user.claims.sub;
      
      if (!documentId) {
        return res.status(400).json({ message: "Document ID is required" });
      }

      const document = await storage.getDocument(documentId);
      if (!document) {
        return res.status(404).json({ message: "Document not found" });
      }

      // Start the LangGraph workflow
      const actualWorkflowId = await langGraphOrchestrator.startDocumentProcessingWorkflow(
        documentId,
        userId
      );

      res.json({
        workflowId: actualWorkflowId,
        documentId,
        documentName: document.fileName,
        status: 'started',
        message: 'Workflow execution started successfully'
      });
    } catch (error) {
      console.error("Error executing workflow:", error);
      res.status(500).json({ message: "Failed to execute workflow: " + error.message });
    }
  });

  // Get journal entries
  app.get('/api/journal-entries', isAuthenticated, async (req: any, res) => {
    try {
      const documentId = req.query.documentId as string;
      const period = req.query.period as string;
      
      let entries;
      if (documentId) {
        entries = await storage.getJournalEntries(documentId);
      } else if (period) {
        entries = await storage.getJournalEntriesByPeriod(period);
      } else {
        entries = await storage.getJournalEntries();
      }
      
      res.json(entries);
    } catch (error) {
      console.error("Error fetching journal entries:", error);
      res.status(500).json({ message: "Failed to fetch journal entries" });
    }
  });

  // Delete journal entry
  app.delete('/api/journal-entries/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const userId = req.user.claims.sub;
      
      await storage.deleteJournalEntry(id);
      
      // Create audit trail
      await storage.createAuditTrail({
        entityType: 'journal_entry',
        entityId: id,
        action: 'delete',
        userId,
        details: { deletedBy: userId }
      });
      
      res.json({ message: "Journal entry deleted successfully" });
    } catch (error) {
      console.error("Error deleting journal entry:", error);
      res.status(500).json({ message: "Failed to delete journal entry" });
    }
  });

  // Get financial statements
  app.get('/api/financial-statements', isAuthenticated, async (req: any, res) => {
    try {
      const type = req.query.type as string;
      const period = req.query.period as string;
      
      let statements;
      if (type && period) {
        statements = await storage.getFinancialStatement(type, period);
      } else {
        statements = await storage.getFinancialStatements(period);
      }
      
      // If no statements exist, generate them from journal entries
      if (!statements || statements.length === 0) {
        const journalEntries = await storage.getJournalEntries();
        
        if (journalEntries.length > 0) {
          // Generate trial balance
          const trialBalance = await generateTrialBalance(journalEntries);
          const trialBalanceStatement = await storage.createFinancialStatement({
            statementType: 'trial_balance',
            period: period || 'Q3_2025',
            data: trialBalance,
            generatedAt: new Date()
          });
          
          // Generate profit & loss
          const profitLoss = await generateProfitLoss(journalEntries);
          const profitLossStatement = await storage.createFinancialStatement({
            statementType: 'profit_loss',
            period: period || 'Q3_2025',
            data: profitLoss,
            generatedAt: new Date()
          });
          
          // Generate balance sheet
          const balanceSheet = await generateBalanceSheet(journalEntries);
          const balanceSheetStatement = await storage.createFinancialStatement({
            statementType: 'balance_sheet',
            period: period || 'Q3_2025',
            data: balanceSheet,
            generatedAt: new Date()
          });
          
          statements = [trialBalanceStatement, profitLossStatement, balanceSheetStatement];
        } else {
          statements = [];
        }
      }
      
      res.json(statements);
    } catch (error) {
      console.error("Error fetching financial statements:", error);
      res.status(500).json({ message: "Failed to fetch financial statements" });
    }
  });

  // Delete financial statement
  app.delete('/api/financial-statements/:id', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const { id } = req.params;
      
      await storage.deleteFinancialStatement(id);
      
      // Log audit trail
      await storage.createAuditTrail({
        action: 'financial_statement_deleted',
        entityType: 'financial_statement',
        entityId: id,
        userId,
        details: { deleted: true },
      });

      res.json({ message: "Financial statement deleted successfully" });
    } catch (error) {
      console.error("Error deleting financial statement:", error);
      res.status(500).json({ message: "Failed to delete financial statement" });
    }
  });

  // Get extracted data for data tables
  app.get('/api/extracted-data', isAuthenticated, async (req: any, res) => {
    try {
      const { period, docType } = req.query;
      const userId = req.user.claims.sub;
      
      console.log('Fetching extracted data for:', { period, docType, userId });
      
      // Get documents based on filters
      const documents = await storage.getDocuments(userId);
      console.log('Found documents:', documents.length);
      
      // For debugging, let's always return data for now
      // Filter by period if specified
      const filteredDocs = documents.filter(doc => {
        if (period && period !== 'all') {
          // Extract period from document metadata or use a default mapping
          const docPeriod = (doc.metadata as any)?.period || 'Q1_2025';
          return docPeriod === period;
        }
        return true;
      });

      console.log('Filtered documents:', filteredDocs.length);

      // Transform documents to extracted data format
      const extractedData = filteredDocs.map(doc => {
        // Use the document type or infer from filename
        const inferredDocType = doc.documentType || inferDocumentType(doc.fileName);
        const sampleData = generateSampleDataForDocument(inferredDocType, doc.fileName);
        
        console.log('Processing document:', doc.fileName, 'Type:', inferredDocType);
        
        return {
          id: doc.id,
          documentId: doc.id,
          documentType: inferredDocType,
          fileName: doc.fileName,
          data: sampleData,
          extractedAt: doc.updatedAt || doc.createdAt,
          confidence: 0.95
        };
      });

      console.log('Extracted data count:', extractedData.length);

      // Filter by document type if specified
      const finalData = docType && docType !== 'all' 
        ? extractedData.filter(item => item.documentType === docType)
        : extractedData;

      console.log('Final data count:', finalData.length);
      res.json(finalData);
    } catch (error) {
      console.error("Error fetching extracted data:", error);
      res.status(500).json({ message: "Failed to fetch extracted data" });
    }
  });

  // Generate journal entries from uploaded documents
  app.post('/api/reports/generate-journal-entries', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const documents = await storage.getDocuments(userId);
      
      let totalEntries = 0;
      let skippedDocuments = 0;
      let processedDocuments = 0;
      
      for (const doc of documents) {
        // Check if journal entries already exist for this document
        const hasExistingEntries = await storage.hasJournalEntries(doc.id);
        
        if (hasExistingEntries) {
          console.log(`Skipping document ${doc.fileName} - journal entries already exist`);
          skippedDocuments++;
          continue;
        }
        
        console.log(`Processing document ${doc.fileName} - no existing journal entries found`);
        
        // Generate sample journal entries based on document type
        const defaultEntries = langGraphOrchestrator.generateDefaultJournalEntries(doc, doc.extractedData);
        
        for (const entry of defaultEntries) {
          await storage.createJournalEntry({
            journalId: entry.journalId,
            date: entry.date,
            accountCode: entry.accountCode,
            accountName: entry.accountName,
            debitAmount: entry.debitAmount,
            creditAmount: entry.creditAmount,
            narration: entry.narration,
            entity: entry.entity,
            documentId: doc.id,
            createdBy: userId,
          });
          totalEntries++;
        }
        processedDocuments++;
      }
      
      const message = totalEntries > 0 
        ? `Generated ${totalEntries} journal entries from ${processedDocuments} documents`
        : skippedDocuments > 0 
          ? `No new journal entries generated. ${skippedDocuments} documents already have journal entries`
          : 'No documents found to process';
      
      res.json({ 
        message,
        totalEntries,
        documentsProcessed: processedDocuments,
        skippedDocuments,
        totalDocuments: documents.length
      });
    } catch (error) {
      console.error("Error generating journal entries:", error);
      res.status(500).json({ message: "Failed to generate journal entries" });
    }
  });

  // Generate trial balance
  app.post('/api/reports/trial-balance', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const { period } = req.body;
      
      let journalEntries = await storage.getJournalEntriesByPeriod(period);
      
      // If no journal entries exist, create them from uploaded documents
      if (journalEntries.length === 0) {
        const documents = await storage.getDocuments(userId);
        
        for (const doc of documents) {
          const defaultEntries = langGraphOrchestrator.generateDefaultJournalEntries(doc, doc.extractedData);
          
          for (const entry of defaultEntries) {
            await storage.createJournalEntry({
              journalId: entry.journalId,
              date: entry.date,
              accountCode: entry.accountCode,
              accountName: entry.accountName,
              debitAmount: entry.debitAmount,
              creditAmount: entry.creditAmount,
              narration: entry.narration,
              entity: entry.entity,
              documentId: doc.id,
              createdBy: userId,
            });
          }
        }
        
        // Fetch the newly created entries
        journalEntries = await storage.getJournalEntriesByPeriod(period);
      }
      
      const trialBalance = await financialReportsService.generateTrialBalance(journalEntries);
      
      // Format numbers as text to bypass frontend rendering issues
      const formattedTrialBalance = {
        ...trialBalance,
        totalDebitsText: formatCurrency(trialBalance.totalDebits),
        totalCreditsText: formatCurrency(trialBalance.totalCredits),
        entries: trialBalance.entries.map((entry: any) => ({
          ...entry,
          debitBalanceText: formatCurrency(entry.debitBalance),
          creditBalanceText: formatCurrency(entry.creditBalance)
        }))
      };
      
      // Save the report
      await storage.createFinancialStatement({
        statementType: 'trial_balance',
        period,
        data: formattedTrialBalance,
        generatedBy: userId,
      });

      res.json(formattedTrialBalance);
    } catch (error) {
      console.error("Error generating trial balance:", error);
      res.status(500).json({ message: "Failed to generate trial balance" });
    }
  });

  // Generate profit & loss statement
  app.post('/api/reports/profit-loss', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const { period } = req.body;
      
      let journalEntries = await storage.getJournalEntriesByPeriod(period);
      
      // If no journal entries exist, create them from uploaded documents
      if (journalEntries.length === 0) {
        const documents = await storage.getDocuments(userId);
        
        for (const doc of documents) {
          const defaultEntries = langGraphOrchestrator.generateDefaultJournalEntries(doc, doc.extractedData);
          
          for (const entry of defaultEntries) {
            await storage.createJournalEntry({
              journalId: entry.journalId,
              date: entry.date,
              accountCode: entry.accountCode,
              accountName: entry.accountName,
              debitAmount: entry.debitAmount,
              creditAmount: entry.creditAmount,
              narration: entry.narration,
              entity: entry.entity,
              documentId: doc.id,
              createdBy: userId,
            });
          }
        }
        
        // Fetch the newly created entries
        journalEntries = await storage.getJournalEntriesByPeriod(period);
      }
      
      const profitLoss = await financialReportsService.generateProfitLoss(journalEntries);
      
      // Save the report
      await storage.createFinancialStatement({
        statementType: 'profit_loss',
        period,
        data: profitLoss,
        generatedBy: userId,
      });

      res.json(profitLoss);
    } catch (error) {
      console.error("Error generating profit & loss:", error);
      res.status(500).json({ message: "Failed to generate profit & loss" });
    }
  });

  // Generate balance sheet
  app.post('/api/reports/balance-sheet', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const { period } = req.body;
      
      let journalEntries = await storage.getJournalEntriesByPeriod(period);
      
      // If no journal entries exist, create them from uploaded documents
      if (journalEntries.length === 0) {
        const documents = await storage.getDocuments(userId);
        
        for (const doc of documents) {
          const defaultEntries = langGraphOrchestrator.generateDefaultJournalEntries(doc, doc.extractedData);
          
          for (const entry of defaultEntries) {
            await storage.createJournalEntry({
              journalId: entry.journalId,
              date: entry.date,
              accountCode: entry.accountCode,
              accountName: entry.accountName,
              debitAmount: entry.debitAmount,
              creditAmount: entry.creditAmount,
              narration: entry.narration,
              entity: entry.entity,
              documentId: doc.id,
              createdBy: userId,
            });
          }
        }
        
        // Fetch the newly created entries
        journalEntries = await storage.getJournalEntriesByPeriod(period);
      }
      
      const balanceSheet = await financialReportsService.generateBalanceSheet(journalEntries);
      
      // Save the report
      await storage.createFinancialStatement({
        statementType: 'balance_sheet',
        period,
        data: balanceSheet,
        generatedBy: userId,
      });

      res.json(balanceSheet);
    } catch (error) {
      console.error("Error generating balance sheet:", error);
      res.status(500).json({ message: "Failed to generate balance sheet" });
    }
  });

  // Get compliance checks
  app.get('/api/compliance-checks', isAuthenticated, async (req: any, res) => {
    try {
      const documentId = req.query.documentId as string;
      const type = req.query.type as string;
      
      let checks;
      if (documentId) {
        checks = await storage.getComplianceChecks(documentId);
      } else if (type) {
        checks = await storage.getComplianceChecksByType(type);
      } else {
        checks = await storage.getComplianceChecks();
      }
      
      res.json(checks);
    } catch (error) {
      console.error("Error fetching compliance checks:", error);
      res.status(500).json({ message: "Failed to fetch compliance checks" });
    }
  });

  // Run compliance check
  app.post('/api/compliance-checks/run', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const { documentId, checkType } = req.body;
      
      const document = await storage.getDocument(documentId);
      if (!document) {
        return res.status(404).json({ message: "Document not found" });
      }

      let validation;
      switch (checkType) {
        case 'gst':
          validation = await complianceCheckerService.validateGSTCompliance(document.extractedData);
          break;
        case 'tds':
          validation = await complianceCheckerService.validateTDSCompliance(document.extractedData);
          break;
        case 'ind_as':
          const journalEntries = await storage.getJournalEntries(documentId);
          validation = await complianceCheckerService.validateIndASCompliance(document, journalEntries);
          break;
        default:
          return res.status(400).json({ message: "Invalid check type" });
      }

      // Save compliance check
      const check = await storage.createComplianceCheck({
        checkType,
        documentId,
        status: validation.isCompliant ? 'compliant' : 'non_compliant',
        findings: validation,
        checkedBy: userId,
      });

      res.json(check);
    } catch (error) {
      console.error("Error running compliance check:", error);
      res.status(500).json({ message: "Failed to run compliance check" });
    }
  });

  // Get audit trail
  app.get('/api/audit-trail', isAuthenticated, async (req: any, res) => {
    try {
      const entityId = req.query.entityId as string;
      const limit = parseInt(req.query.limit as string) || 50;
      
      let trail;
      if (entityId) {
        trail = await storage.getAuditTrail(entityId);
      } else {
        trail = await storage.getRecentAuditTrail(limit);
      }
      
      res.json(trail);
    } catch (error) {
      console.error("Error fetching audit trail:", error);
      res.status(500).json({ message: "Failed to fetch audit trail" });
    }
  });

  // Get dashboard statistics
  app.get('/api/dashboard/stats', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const stats = await storage.getDashboardStats(userId);
      res.json(stats);
    } catch (error) {
      console.error("Error fetching dashboard stats:", error);
      res.status(500).json({ message: "Failed to fetch dashboard stats" });
    }
  });

  // Data Source Configuration Endpoints
  
  // Get data source statistics (must be before the :id route)
  app.get('/api/data-sources/stats', isAuthenticated, async (req: any, res) => {
    try {
      const stats = await dataSourceService.getDataSourceStats();
      res.json(stats);
    } catch (error) {
      console.error("Error fetching data source stats:", error);
      res.status(500).json({ message: "Failed to fetch stats" });
    }
  });

  // Get all data sources
  app.get('/api/data-sources', isAuthenticated, async (req: any, res) => {
    try {
      const sources = await dataSourceService.getAllDataSources();
      res.json(sources);
    } catch (error) {
      console.error("Error fetching data sources:", error);
      res.status(500).json({ message: "Failed to fetch data sources" });
    }
  });

  // Get specific data source
  app.get('/api/data-sources/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const source = await dataSourceService.getDataSource(id);
      if (!source) {
        return res.status(404).json({ message: "Data source not found" });
      }
      res.json(source);
    } catch (error) {
      console.error("Error fetching data source:", error);
      res.status(500).json({ message: "Failed to fetch data source" });
    }
  });

  // Create new data source
  app.post('/api/data-sources', isAuthenticated, async (req: any, res) => {
    try {
      const source = await dataSourceService.createDataSource(req.body);
      res.json(source);
    } catch (error) {
      console.error("Error creating data source:", error);
      res.status(500).json({ message: "Failed to create data source" });
    }
  });

  // Update data source
  app.put('/api/data-sources/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const source = await dataSourceService.updateDataSource(id, req.body);
      if (!source) {
        return res.status(404).json({ message: "Data source not found" });
      }
      res.json(source);
    } catch (error) {
      console.error("Error updating data source:", error);
      res.status(500).json({ message: "Failed to update data source" });
    }
  });

  // Test data source connection
  app.post('/api/data-sources/:id/test', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const result = await dataSourceService.testConnection(id);
      res.json(result);
    } catch (error) {
      console.error("Error testing data source connection:", error);
      res.status(500).json({ message: "Failed to test connection" });
    }
  });

  // ERP Connector Endpoints
  
  // Get ERP statistics (must be before the :id route)
  app.get('/api/erp-connectors/stats', isAuthenticated, async (req: any, res) => {
    try {
      const stats = await dataSourceService.getERPStats();
      res.json(stats);
    } catch (error) {
      console.error("Error fetching ERP stats:", error);
      res.status(500).json({ message: "Failed to fetch ERP stats" });
    }
  });

  // Get all ERP connectors
  app.get('/api/erp-connectors', isAuthenticated, async (req: any, res) => {
    try {
      const connectors = await dataSourceService.getAllERPConnectors();
      res.json(connectors);
    } catch (error) {
      console.error("Error fetching ERP connectors:", error);
      res.status(500).json({ message: "Failed to fetch ERP connectors" });
    }
  });

  // Get specific ERP connector
  app.get('/api/erp-connectors/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const connector = await dataSourceService.getERPConnector(id);
      if (!connector) {
        return res.status(404).json({ message: "ERP connector not found" });
      }
      res.json(connector);
    } catch (error) {
      console.error("Error fetching ERP connector:", error);
      res.status(500).json({ message: "Failed to fetch ERP connector" });
    }
  });

  // Update ERP connector
  app.put('/api/erp-connectors/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const connector = await dataSourceService.updateERPConnector(id, req.body);
      if (!connector) {
        return res.status(404).json({ message: "ERP connector not found" });
      }
      res.json(connector);
    } catch (error) {
      console.error("Error updating ERP connector:", error);
      res.status(500).json({ message: "Failed to update ERP connector" });
    }
  });

  // Sync ERP data
  app.post('/api/erp-connectors/:id/sync', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const result = await dataSourceService.syncERPData(id);
      res.json(result);
    } catch (error) {
      console.error("Error syncing ERP data:", error);
      res.status(500).json({ message: "Failed to sync ERP data" });
    }
  });

  // Data Format Template Endpoints
  
  // Get all data format templates
  app.get('/api/data-formats', isAuthenticated, async (req: any, res) => {
    try {
      const type = req.query.type as string;
      let formats;
      
      if (type) {
        formats = await dataSourceService.getDataFormatsByType(type as any);
      } else {
        formats = await dataSourceService.getAllDataFormats();
      }
      
      res.json(formats);
    } catch (error) {
      console.error("Error fetching data formats:", error);
      res.status(500).json({ message: "Failed to fetch data formats" });
    }
  });

  // Get specific data format template
  app.get('/api/data-formats/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const format = await dataSourceService.getDataFormat(id);
      if (!format) {
        return res.status(404).json({ message: "Data format not found" });
      }
      res.json(format);
    } catch (error) {
      console.error("Error fetching data format:", error);
      res.status(500).json({ message: "Failed to fetch data format" });
    }
  });

  // Master Data Endpoints
  
  // Get all master data
  app.get('/api/master-data', isAuthenticated, async (req: any, res) => {
    try {
      const type = req.query.type as string;
      let masterData;
      
      if (type) {
        masterData = await dataSourceService.getMasterDataByType(type as any);
      } else {
        masterData = await dataSourceService.getAllMasterData();
      }
      
      res.json(masterData);
    } catch (error) {
      console.error("Error fetching master data:", error);
      res.status(500).json({ message: "Failed to fetch master data" });
    }
  });

  // Get specific master data
  app.get('/api/master-data/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const masterData = await dataSourceService.getMasterData(id);
      if (!masterData) {
        return res.status(404).json({ message: "Master data not found" });
      }
      res.json(masterData);
    } catch (error) {
      console.error("Error fetching master data:", error);
      res.status(500).json({ message: "Failed to fetch master data" });
    }
  });

  // Update master data
  app.put('/api/master-data/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const { data } = req.body;
      const masterData = await dataSourceService.updateMasterData(id, data);
      if (!masterData) {
        return res.status(404).json({ message: "Master data not found" });
      }
      res.json(masterData);
    } catch (error) {
      console.error("Error updating master data:", error);
      res.status(500).json({ message: "Failed to update master data" });
    }
  });

  // AI Learning Initialization
  app.post('/api/ai-learning/initialize', isAuthenticated, async (req: any, res) => {
    try {
      const result = await dataSourceService.initializeAILearning();
      res.json(result);
    } catch (error) {
      console.error("Error initializing AI learning:", error);
      res.status(500).json({ message: "Failed to initialize AI learning" });
    }
  });

  // Test route to manually create journal entries for existing documents
  app.post('/api/test/create-journal-entries', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const documents = await storage.getDocuments(userId);
      
      let totalEntries = 0;
      
      for (const document of documents) {
        // Create sample journal entries for each document
        const defaultEntries = [
          {
            journalId: `JE${Date.now()}_${document.id}_1`,
            date: new Date(),
            accountCode: 'EXPENSE',
            accountName: 'Document Processing Expense',
            debitAmount: "1000",
            creditAmount: "0",
            narration: `Processing document: ${document.originalName}`,
            entity: 'System',
            documentId: document.id,
            createdBy: userId,
          },
          {
            journalId: `JE${Date.now()}_${document.id}_2`,
            date: new Date(),
            accountCode: 'PAYABLE',
            accountName: 'Accounts Payable',
            debitAmount: "0",
            creditAmount: "1000",
            narration: `Processing document: ${document.originalName}`,
            entity: 'System',
            documentId: document.id,
            createdBy: userId,
          }
        ];
        
        for (const entry of defaultEntries) {
          await storage.createJournalEntry(entry);
          totalEntries++;
        }
      }
      
      res.json({ message: `Created ${totalEntries} journal entries`, documents: documents.length });
    } catch (error) {
      console.error("Error creating test journal entries:", error);
      res.status(500).json({ message: "Failed to create journal entries" });
    }
  });

  // Static file serving for uploads
  app.use('/uploads', express.static('uploads'));

  // ML Model Management endpoints
  app.get('/api/ml/models', isAuthenticated, async (req: any, res) => {
    try {
      // Return sample model data
      const models = [
        {
          id: '1',
          model_name: 'Default Anomaly Model',
          name: 'Default Anomaly Model',
          version: '1.0.0',
          status: 'active',
          accuracy: 85.5,
          lastTrained: new Date().toISOString(),
          modelType: 'isolation_forest',
          model_type: 'isolation_forest',
          training_data_size: 1000,
          training_date: new Date().toISOString(),
          is_active: true,
          created_at: new Date().toISOString(),
          performance_metrics: {
            accuracy: 85.5,
            precision: 87.2,
            recall: 83.1
          }
        }
      ];
      res.json(models);
    } catch (error) {
      console.error("Error fetching ML models:", error);
      res.status(500).json({ message: "Failed to fetch ML models" });
    }
  });

  app.post('/api/ml/models/train', isAuthenticated, async (req: any, res) => {
    try {
      const { model_name, model_types, training_data_days, contamination_rate } = req.body;
      const userId = req.user.claims.sub;
      
      // Get journal entries for training
      const journalEntries = await storage.getJournalEntries();
      
      if (journalEntries.length < 10) {
        return res.status(400).json({ 
          message: "Insufficient training data. Need at least 10 journal entries." 
        });
      }

      // Simulate training process
      const trainingResult = {
        model_name,
        training_samples: journalEntries.length,
        status: 'completed',
        accuracy: 92.3,
        model_types: model_types || ['isolation_forest'],
        training_time: '2.5 minutes',
        contamination_rate: contamination_rate || 0.1
      };

      res.json(trainingResult);
    } catch (error) {
      console.error("Error training model:", error);
      res.status(500).json({ message: "Failed to train model" });
    }
  });

  app.post('/api/ml/anomalies/detect', isAuthenticated, async (req: any, res) => {
    try {
      const { model_name, document_ids, ensemble_method } = req.body;
      const userId = req.user.claims.sub;
      
      if (!document_ids || document_ids.length === 0) {
        return res.status(400).json({ message: "No documents selected for analysis" });
      }

      // Get documents and their journal entries
      const docResults = await Promise.all(
        document_ids.map((id: string) => storage.getDocument(id))
      );
      
      const validDocuments = docResults.filter(doc => doc !== null);
      
      if (validDocuments.length === 0) {
        return res.status(404).json({ message: "No valid documents found" });
      }

      // Get journal entries for these documents
      const allJournalEntries = await storage.getJournalEntries();
      const documentJournalEntries = allJournalEntries.filter(entry => 
        document_ids.includes(entry.documentId)
      );

      // Perform basic anomaly detection
      const anomalies = [];
      for (const document of validDocuments) {
        const documentEntries = documentJournalEntries.filter(entry => 
          entry.documentId === document.id
        );
        
        const docAnomalies = await performBasicAnomalyDetection(documentEntries, document);
        anomalies.push(...docAnomalies);
      }

      res.json({
        model_name,
        anomalies,
        documents_analyzed: validDocuments.length,
        total_transactions: documentJournalEntries.length,
        ensemble_method: ensemble_method || 'voting',
        analysis_timestamp: new Date().toISOString()
      });
    } catch (error) {
      console.error("Error detecting anomalies:", error);
      res.status(500).json({ message: "Failed to detect anomalies" });
    }
  });

  app.get('/api/ml/anomalies', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      
      // Get recent anomalies (mock data for now)
      const anomalies = [
        {
          id: '1',
          transactionId: 'TXN-001',
          documentId: 'DOC-001',
          anomalyScore: 85.2,
          confidence: 0.89,
          anomalyType: 'amount_anomaly',
          severity: 'HIGH',
          reasoning: 'Transaction amount significantly exceeds normal range',
          detectedAt: new Date().toISOString(),
          status: 'pending_review'
        }
      ];
      
      res.json(anomalies);
    } catch (error) {
      console.error("Error fetching anomalies:", error);
      res.status(500).json({ message: "Failed to fetch anomalies" });
    }
  });

  app.get('/api/ml/monitoring/alerts', isAuthenticated, async (req: any, res) => {
    try {
      const alerts = [
        {
          id: '1',
          type: 'high_anomaly_rate',
          message: 'Anomaly detection rate increased by 15% in the last 24 hours',
          severity: 'warning',
          timestamp: new Date().toISOString()
        }
      ];
      res.json(alerts);
    } catch (error) {
      console.error("Error fetching monitoring alerts:", error);
      res.status(500).json({ message: "Failed to fetch monitoring alerts" });
    }
  });

  app.get('/api/ml/monitoring/performance', isAuthenticated, async (req: any, res) => {
    try {
      const performance = [
        {
          model_name: "Default Anomaly Model",
          metric_name: "accuracy",
          metric_value: 92.3,
          metric_type: "percentage",
          measurement_date: new Date().toISOString(),
          samples_processed: 1000,
          anomalies_detected: 12,
          processing_time_ms: 1200
        },
        {
          model_name: "Default Anomaly Model",
          metric_name: "precision",
          metric_value: 87.5,
          metric_type: "percentage",
          measurement_date: new Date().toISOString(),
          samples_processed: 1000,
          anomalies_detected: 12,
          processing_time_ms: 1150
        },
        {
          model_name: "Default Anomaly Model",
          metric_name: "recall",
          metric_value: 89.2,
          metric_type: "percentage",
          measurement_date: new Date().toISOString(),
          samples_processed: 1000,
          anomalies_detected: 12,
          processing_time_ms: 1180
        }
      ];
      res.json(performance);
    } catch (error) {
      console.error("Error fetching performance metrics:", error);
      res.status(500).json({ message: "Failed to fetch performance metrics" });
    }
  });

  // Agentic Anomaly Detection endpoints
  app.post('/api/ml/anomalies/analyze', isAuthenticated, async (req: any, res) => {
    try {
      const { documents, documentId, useAI = true, includeHistoricalData = true, analysisType = 'comprehensive' } = req.body;
      const userId = req.user.claims.sub;
      
      // Handle both single document and multiple documents
      const documentIds = documents || (documentId ? [documentId] : []);
      
      if (documentIds.length === 0) {
        return res.status(400).json({ message: 'No documents provided for analysis' });
      }
      
      // Get documents and related transactions
      const documentResults = await Promise.all(
        documentIds.map((id: string) => storage.getDocument(id))
      );
      
      const validDocuments = documentResults.filter(doc => doc !== null);
      
      if (validDocuments.length === 0) {
        return res.status(404).json({ message: 'No valid documents found' });
      }
      
      // Get journal entries for all documents
      const allJournalEntries = await storage.getJournalEntries();
      const journalEntries = allJournalEntries.filter(entry => 
        documentIds.includes(entry.documentId)
      );
      
      if (useAI) {
        try {
          const { anomalyDetectionAgent } = await import('./services/anomalyAgent');
          
          // Get historical data (use existing journal entries as fallback)
          const historicalData = allJournalEntries.slice(0, 100); // Use recent entries as historical data
          
          const analysisRequest = {
            transactions: journalEntries,
            document: validDocuments[0], // Use first document for compatibility
            documents: validDocuments,
            historicalData,
            complianceRules: [], // Use empty array as fallback
            userContext: `User: ${userId}, Documents: ${validDocuments.length}`
          };
          
          const anomalies = await anomalyDetectionAgent.analyzeTransactionAnomalies(analysisRequest);
          
          // Generate comprehensive insights
          const insights = await anomalyDetectionAgent.generateAnomalyInsights(anomalies, {
            documents: validDocuments,
            transactionCount: journalEntries.length,
            userId,
            analysisType
          });
          
          res.json({
            anomalies,
            insights,
            analysisType: 'agentic',
            documentsAnalyzed: validDocuments.length,
            transactionCount: journalEntries.length,
            timestamp: new Date()
          });
        } catch (error) {
          console.error('AI analysis failed, falling back to basic analysis:', error);
          // Fallback to basic analysis if AI fails
          const anomalies = [];
          for (const document of validDocuments) {
            const docEntries = journalEntries.filter(entry => entry.documentId === document.id);
            const docAnomalies = await performBasicAnomalyDetection(docEntries, document);
            anomalies.push(...docAnomalies);
          }
          
          res.json({
            anomalies,
            analysisType: 'statistical_fallback',
            documentsAnalyzed: validDocuments.length,
            transactionCount: journalEntries.length,
            timestamp: new Date(),
            note: 'AI analysis failed, used statistical fallback'
          });
        }
      } else {
        // Basic statistical analysis
        const anomalies = [];
        for (const document of validDocuments) {
          const docEntries = journalEntries.filter(entry => entry.documentId === document.id);
          const docAnomalies = await performBasicAnomalyDetection(docEntries, document);
          anomalies.push(...docAnomalies);
        }
        
        res.json({
          anomalies,
          analysisType: 'statistical',
          documentsAnalyzed: validDocuments.length,
          transactionCount: journalEntries.length,
          timestamp: new Date()
        });
      }
    } catch (error) {
      console.error('Error analyzing anomalies:', error);
      res.status(500).json({ message: 'Failed to analyze anomalies' });
    }
  });

  app.post('/api/ml/anomalies/explain', jwtAuth, async (req: any, res) => {
    try {
      const { anomaly_id, anomalyId, question } = req.body;
      const targetAnomalyId = anomaly_id || anomalyId;
      
      // For now, use mock data since we don't have full database integration
      const mockAnomalies = [
        {
          id: '1',
          transactionId: 'TXN-001',
          documentId: 'DOC-001',
          anomalyScore: 85.2,
          confidence: 0.89,
          anomalyType: 'amount_anomaly',
          severity: 'HIGH' as const,
          reasoning: 'Transaction amount significantly exceeds normal range',
          evidence: ['Amount exceeds 2 standard deviations', 'No historical precedent'],
          recommendations: ['Review transaction', 'Verify documentation'],
          businessContext: 'Statistical outlier detection',
          riskFactors: ['Unusual amount'],
          suggestedActions: [],
          followUpQuestions: ['Is this amount correct?'],
          relatedTransactions: [],
          detectedAt: new Date().toISOString(),
          status: 'pending_review'
        }
      ];
      
      const anomaly = mockAnomalies.find(a => a.id === targetAnomalyId);
      if (!anomaly) {
        return res.status(404).json({ message: 'Anomaly not found' });
      }
      
      try {
        const { anomalyDetectionAgent } = await import('./services/anomalyAgent');
        const explanation = await anomalyDetectionAgent.explainAnomalyToUser(anomaly, question);
        res.json({ explanation });
      } catch (importError) {
        console.warn('Anomaly agent not available, using fallback explanation');
        // Fallback explanation
        const fallbackExplanation = `This transaction (${anomaly.transactionId}) was flagged as an anomaly because:\n\n` +
          ` Anomaly Score: ${anomaly.anomalyScore}/100 (${anomaly.severity} severity)\n` +
          ` Confidence Level: ${(anomaly.confidence * 100).toFixed(1)}%\n` +
          ` Reason: ${anomaly.reasoning}\n\n` +
          `The system detected unusual patterns in this transaction that deviate from normal behavior. ` +
          `This could indicate data entry errors, fraudulent activity, or legitimate but unusual business transactions that require review.`;
        
        res.json({ explanation: fallbackExplanation });
      }
    } catch (error) {
      console.error('Error explaining anomaly:', error);
      res.status(500).json({ message: 'Failed to explain anomaly' });
    }
  });

  app.post('/api/ml/anomalies/remediate', jwtAuth, async (req: any, res) => {
    try {
      const { anomalyId } = req.body;
      
      // Mock anomaly data for now
      const mockAnomalies = [
        {
          id: '1',
          transactionId: 'TXN-001',
          documentId: 'DOC-001',
          anomalyScore: 85.2,
          confidence: 0.89,
          anomalyType: 'amount_anomaly',
          severity: 'HIGH' as const,
          reasoning: 'Transaction amount significantly exceeds normal range',
          evidence: ['Amount exceeds 2 standard deviations', 'No historical precedent'],
          recommendations: ['Review transaction', 'Verify documentation'],
          businessContext: 'Statistical outlier detection',
          riskFactors: ['Unusual amount'],
          suggestedActions: [],
          followUpQuestions: ['Is this amount correct?'],
          relatedTransactions: []
        }
      ];
      
      const anomaly = mockAnomalies.find(a => a.id === anomalyId);
      if (!anomaly) {
        return res.status(404).json({ message: 'Anomaly not found' });
      }
      
      try {
        const { anomalyDetectionAgent } = await import('./services/anomalyAgent');
        const actions = await anomalyDetectionAgent.suggestRemediationActions(anomaly);
        res.json({ actions });
      } catch (importError) {
        console.warn('Anomaly agent not available, using fallback remediation');
        // Fallback remediation suggestions
        const fallbackActions = [
          {
            action: 'Review Transaction Details',
            description: 'Manually verify the transaction amount and supporting documentation',
            priority: 'HIGH',
            category: 'validation'
          },
          {
            action: 'Check Source Documents',
            description: 'Cross-reference with original invoices or receipts',
            priority: 'MEDIUM',
            category: 'verification'
          },
          {
            action: 'Flag for Approval',
            description: 'Route to supervisor for additional review and approval',
            priority: 'LOW',
            category: 'escalation'
          }
        ];
        
        res.json({ actions: fallbackActions });
      }
    } catch (error) {
      console.error('Error suggesting remediation:', error);
      res.status(500).json({ message: 'Failed to suggest remediation' });
    }
  });

  app.get('/api/ml/anomalies/patterns', jwtAuth, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const timeframe = req.query.timeframe as string || '30d';
      
      // Mock recent anomalies for now
      const mockRecentAnomalies = [
        {
          id: '1',
          transactionId: 'TXN-001',
          documentId: 'DOC-001',
          anomalyScore: 85.2,
          confidence: 0.89,
          anomalyType: 'amount_anomaly',
          severity: 'HIGH' as const,
          reasoning: 'Transaction amount significantly exceeds normal range',
          evidence: ['Amount exceeds 2 standard deviations', 'No historical precedent'],
          recommendations: ['Review transaction', 'Verify documentation'],
          businessContext: 'Statistical outlier detection',
          riskFactors: ['Unusual amount'],
          suggestedActions: [],
          followUpQuestions: ['Is this amount correct?'],
          relatedTransactions: [],
          detectedAt: new Date().toISOString(),
          status: 'pending_review'
        }
      ];
      
      try {
        const { anomalyDetectionAgent } = await import('./services/anomalyAgent');
        const insights = await anomalyDetectionAgent.generateAnomalyInsights(mockRecentAnomalies, {
          userId,
          timeframe
        });
        
        res.json({
          patterns: insights.patternAnalysis,
          riskScore: insights.overallRiskScore,
          recommendations: insights.recommendations,
          complianceIssues: insights.complianceIssues
        });
      } catch (importError) {
        console.warn('Anomaly agent not available, using fallback patterns');
        // Fallback pattern analysis
        const fallbackPatterns = {
          patterns: [
            {
              type: 'amount_anomaly',
              frequency: 5,
              severity: 'HIGH',
              description: 'Transactions with amounts significantly above normal range',
              trend: 'increasing'
            },
            {
              type: 'timing_anomaly',
              frequency: 3,
              severity: 'MEDIUM',
              description: 'Transactions occurring outside normal business hours',
              trend: 'stable'
            }
          ],
          riskScore: 7.2,
          recommendations: [
            'Review high-value transactions for accuracy',
            'Implement additional controls for after-hours transactions',
            'Consider automated approval workflows for anomalous transactions'
          ],
          complianceIssues: [
            'Some transactions may require additional documentation',
            'Review needed for transactions exceeding approval limits'
          ]
        };
        
        res.json(fallbackPatterns);
      }
    } catch (error) {
      console.error('Error getting anomaly patterns:', error);
      res.status(500).json({ message: 'Failed to get anomaly patterns' });
    }
  });

  // Reconciliation routes
  app.post('/api/reconciliation/run', isAuthenticated, async (req: any, res) => {
    try {
      const { period, entityList, useAdvanced = false } = req.body;
      const userId = req.user.claims.sub;
      
      let report;
      if (useAdvanced) {
        const { advancedReconciliationEngine } = await import('./services/advancedReconciliation');
        const matches = await advancedReconciliationEngine.performAdvancedReconciliation(period, entityList);
        
        // Generate comprehensive report with advanced insights
        const { anthropicService } = await import('./services/anthropicService');
        const analysis = await anthropicService.analyzeReconciliationResults(matches);
        const adjustments = await anthropicService.generateReconciliationAdjustments(matches);
        
        report = {
          period,
          totalTransactions: matches.length * 2, // Rough estimate
          matchedTransactions: matches.length,
          unmatchedTransactions: 0, // Will be calculated properly
          disputedTransactions: matches.filter(m => m.matchScore < 0.8).length,
          totalVariance: matches.reduce((sum, m) => sum + m.variance, 0),
          reconciliationRate: matches.length > 0 ? (matches.filter(m => m.matchScore > 0.8).length / matches.length) * 100 : 0,
          recommendations: analysis.recommendations,
          matches,
          insights: analysis.insights,
          riskAreas: analysis.riskAreas,
          dataQualityIssues: analysis.dataQualityIssues,
          adjustments: adjustments.adjustments,
          algorithmType: 'advanced',
          timestamp: new Date()
        };
      } else {
        const { reconciliationEngine } = await import('./services/reconciliationEngine');
        report = await reconciliationEngine.performReconciliation(period, entityList);
        (report as any).algorithmType = 'standard';
        (report as any).timestamp = new Date();
      }
      
      // Save report to database
      await storage.createReconciliationReport({
        period,
        totalTransactions: report.totalTransactions,
        matchedTransactions: report.matchedTransactions,
        unmatchedTransactions: report.unmatchedTransactions,
        disputedTransactions: report.disputedTransactions,
        totalVariance: report.totalVariance.toString(),
        reconciliationRate: report.reconciliationRate.toString(),
        recommendations: report.recommendations,
        reportData: report,
        createdBy: userId,
      });
      
      res.json(report);
    } catch (error) {
      console.error('Error running reconciliation:', error);
      res.status(500).json({ message: 'Failed to run reconciliation' });
    }
  });

  app.get('/api/reconciliation/reports', isAuthenticated, async (req: any, res) => {
    try {
      const period = req.query.period as string;
      const reports = await storage.getReconciliationReports(period);
      res.json(reports);
    } catch (error) {
      console.error('Error fetching reconciliation reports:', error);
      res.status(500).json({ message: 'Failed to fetch reconciliation reports' });
    }
  });

  app.get('/api/reconciliation/matches', isAuthenticated, async (req: any, res) => {
    try {
      const period = req.query.period as string;
      const matches = await storage.getReconciliationMatches(period);
      res.json(matches);
    } catch (error) {
      console.error('Error fetching reconciliation matches:', error);
      res.status(500).json({ message: 'Failed to fetch reconciliation matches' });
    }
  });

  app.get('/api/reconciliation/rules', isAuthenticated, async (req: any, res) => {
    try {
      const { reconciliationEngine } = await import('./services/reconciliationEngine');
      const rules = await reconciliationEngine.getReconciliationRules();
      res.json(rules);
    } catch (error) {
      console.error('Error fetching reconciliation rules:', error);
      res.status(500).json({ message: 'Failed to fetch reconciliation rules' });
    }
  });

  app.post('/api/reconciliation/rules', isAuthenticated, async (req: any, res) => {
    try {
      const { reconciliationEngine } = await import('./services/reconciliationEngine');
      await reconciliationEngine.updateReconciliationRule(req.body);
      res.json({ message: 'Rule updated successfully' });
    } catch (error) {
      console.error('Error updating reconciliation rule:', error);
      res.status(500).json({ message: 'Failed to update reconciliation rule' });
    }
  });

  app.get('/api/intercompany/transactions', isAuthenticated, async (req: any, res) => {
    try {
      const period = req.query.period as string;
      const transactions = await storage.getIntercompanyTransactions(period);
      res.json(transactions);
    } catch (error) {
      console.error('Error fetching intercompany transactions:', error);
      res.status(500).json({ message: 'Failed to fetch intercompany transactions' });
    }
  });

  // Agent Chat API endpoints
  app.post('/api/agent-chat/start', isAuthenticated, async (req: any, res) => {
    try {
      const { message, documentId } = req.body;
      const userId = req.user.claims.sub;
      
      let documentName = 'All Documents';
      let workflowId = `workflow-${Date.now()}`;
      
      if (documentId) {
        const document = await storage.getDocument(documentId);
        if (!document) {
          return res.status(404).json({ message: "Document not found" });
        }
        documentName = document.fileName || 'Unknown Document';
        
        // Try to start the actual LangGraph workflow
        try {
          workflowId = await langGraphOrchestrator.startDocumentProcessingWorkflow(
            documentId,
            userId
          );
          
          res.json({
            workflowId,
            documentName,
            status: 'started',
            message: 'Workflow started successfully'
          });
        } catch (workflowError) {
          console.error("LangGraph workflow start failed:", workflowError);
          // Fall back to mock workflow if LangGraph fails
          res.json({
            workflowId,
            documentName,
            status: 'started',
            message: 'Workflow started in demo mode (LangGraph temporarily unavailable)'
          });
        }
      } else {
        // No specific document - return general response
        res.json({
          workflowId,
          documentName,
          status: 'started',
          message: 'General workflow started - select a document to process'
        });
      }
    } catch (error) {
      console.error("Error starting agent workflow:", error);
      res.status(500).json({ message: "Failed to start workflow" });
    }
  });

  app.post('/api/agent-chat/stop', isAuthenticated, async (req: any, res) => {
    try {
      // Stop the current workflow
      res.json({
        status: 'stopped',
        message: 'Workflow stopped successfully'
      });
    } catch (error) {
      console.error("Error stopping agent workflow:", error);
      res.status(500).json({ message: "Failed to stop workflow" });
    }
  });

  app.post('/api/agent-chat/message', isAuthenticated, async (req: any, res) => {
    try {
      const { message } = req.body;
      const userId = req.user.claims.sub;
      
      // Simple message processing
      let response = "I received your message. ";
      let agentName = "System";
      
      if (message.toLowerCase().includes('status')) {
        response += "All agents are currently operational. Use 'start' to begin processing documents.";
        agentName = "StatusBot";
      } else if (message.toLowerCase().includes('help')) {
        response += "Available commands: 'start' to begin workflow, 'status' for agent status, 'stop' to halt processing.";
        agentName = "HelpBot";
      } else {
        response += "I understand you want to work with the financial documents. Try saying 'start' to begin processing.";
        agentName = "AssistantBot";
      }
      
      res.json({
        response,
        agentName,
        timestamp: new Date().toISOString()
      });
    } catch (error) {
      console.error("Error processing chat message:", error);
      res.status(500).json({ message: "Failed to process message" });
    }
  });

  // Settings routes
  app.get('/api/settings', isAuthenticated, async (req, res) => {
    try {
      const userId = (req as any).user?.claims?.sub;
      let settings = await storage.getSettings(userId);
      
      // Return default settings if none exist
      if (!settings) {
        settings = {
          id: `settings_${userId}`,
          userId,
          apiKeys: {
            openai: process.env.OPENAI_API_KEY ? "" : "",
            anthropic: process.env.ANTHROPIC_API_KEY ? "" : "",
            pinecone: process.env.PINECONE_API_KEY || "",
            postgres: process.env.DATABASE_URL ? "" : "",
          },
          aiSettings: {
            temperature: 0.7,
            maxTokens: 4000,
            model: "claude-sonnet-4-20250514",
            systemPrompt: "You are a helpful AI assistant specialized in financial document processing and analysis for Indian enterprises. You understand GST, TDS, IndAS, and Companies Act 2013 compliance requirements.",
            enableStreaming: true,
            responseFormat: "json",
          },
          agentConfigs: {
            classifierBot: {
              temperature: 0.1,
              maxTokens: 2000,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are ClassifierBot, an expert at identifying and classifying financial documents. Your role is to analyze document content and accurately categorize them into types like vendor invoices, sales registers, bank statements, GST returns, TDS certificates, and salary registers. Focus on precision and consistency in classification.",
              enabled: true,
            },
            journalBot: {
              temperature: 0.3,
              maxTokens: 3000,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are JournalBot, specialized in creating accurate double-entry journal entries from financial documents. You understand Indian accounting standards (IndAS), GST implications, and TDS provisions. Generate precise debit/credit entries with proper account codes and ensure all transactions balance.",
              enabled: true,
            },
            gstValidator: {
              temperature: 0.2,
              maxTokens: 2500,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are GSTValidator, an expert in Indian GST compliance. Validate GST calculations, HSN codes, tax rates, input tax credit eligibility, and ensure compliance with GSTR-1, GSTR-3B requirements. Check for reverse charge mechanism and interstate vs intrastate transactions.",
              enabled: true,
            },
            tdsValidator: {
              temperature: 0.2,
              maxTokens: 2500,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are TDSValidator, focused on TDS compliance per Indian Income Tax Act. Validate TDS rates, PAN requirements, nature of payments, quarterly return compliance (Form 26Q), and ensure proper TDS deduction and deposit timelines.",
              enabled: true,
            },
            dataExtractor: {
              temperature: 0.4,
              maxTokens: 4000,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are DataExtractor, specialized in extracting structured data from financial documents. Extract key information like amounts, dates, vendor details, invoice numbers, tax components, and payment terms. Ensure data accuracy and completeness for downstream processing.",
              enabled: true,
            },
            consoAI: {
              temperature: 0.3,
              maxTokens: 3500,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are ConsoAI, responsible for consolidating financial data and generating comprehensive financial statements. Create trial balances, profit & loss statements, balance sheets, and cash flow statements. Ensure compliance with Indian accounting standards and regulatory requirements.",
              enabled: true,
            },
            auditAgent: {
              temperature: 0.1,
              maxTokens: 3000,
              model: "claude-sonnet-4-20250514",
              systemPrompt: "You are AuditAgent, the final validation layer for all financial processing. Perform comprehensive audit checks, identify discrepancies, validate calculations, ensure regulatory compliance, and provide detailed audit trails. Flag any anomalies or compliance issues.",
              enabled: true,
            },
          },
          vectorDatabase: {
            provider: "pinecone",
            indexName: "financial-documents",
            dimension: 1536,
            metric: "cosine",
            namespace: "default",
            topK: 10,
            enableHybridSearch: true,
          },
          security: {
            enableRateLimit: true,
            rateLimitRequests: 100,
            rateLimitWindow: 60,
            enableApiKeyRotation: false,
            rotationInterval: 30,
            enableAuditLog: true,
          },
          processing: {
            enableParallelProcessing: true,
            maxConcurrentJobs: 5,
            retryAttempts: 3,
            timeoutSeconds: 300,
            enableAutoClassification: true,
            confidenceThreshold: 0.8,
          },
          notifications: {
            emailEnabled: false,
            slackEnabled: false,
            webhookUrl: "",
            notifyOnCompletion: true,
            notifyOnError: true,
            notifyOnThreshold: false,
          },
          compliance: {
            enableDataRetention: true,
            retentionDays: 90,
            enableEncryption: true,
            enablePIIDetection: true,
            enableComplianceReports: true,
          },
          createdAt: new Date().toISOString(),
          updatedAt: new Date().toISOString(),
        };
        await storage.createSettings(settings);
      }
      
      res.json(settings);
    } catch (error) {
      console.error("Error fetching settings:", error);
      res.status(500).json({ message: "Failed to fetch settings" });
    }
  });

  app.put('/api/settings', isAuthenticated, async (req, res) => {
    try {
      const userId = (req as any).user?.claims?.sub;
      const settingsData = req.body;
      
      // Validate required fields
      if (!settingsData.id) {
        return res.status(400).json({ message: "Settings ID is required" });
      }
      
      const updatedSettings = await storage.updateSettings(settingsData.id, {
        ...settingsData,
        userId,
        updatedAt: new Date().toISOString(),
      });
      
      res.json(updatedSettings);
    } catch (error) {
      console.error("Error updating settings:", error);
      res.status(500).json({ message: "Failed to update settings" });
    }
  });

  app.post('/api/settings/test-connection/:provider', isAuthenticated, async (req, res) => {
    try {
      const { provider } = req.params;
      const userId = (req as any).user?.claims?.sub;
      
      // Get current settings
      const settings = await storage.getSettings(userId);
      if (!settings) {
        return res.status(404).json({ message: "Settings not found" });
      }
      
      let connectionResult = { success: false, message: "" };
      
      switch (provider) {
        case 'openai':
          connectionResult = { success: !!process.env.OPENAI_API_KEY, message: process.env.OPENAI_API_KEY ? "OpenAI API key is configured" : "OpenAI API key not found" };
          break;
          
        case 'anthropic':
          connectionResult = { success: !!process.env.ANTHROPIC_API_KEY, message: process.env.ANTHROPIC_API_KEY ? "Anthropic API key is configured" : "Anthropic API key not found" };
          break;
          
        case 'pinecone':
          connectionResult = { success: true, message: "Pinecone connection test not implemented" };
          break;
          
        case 'postgres':
          connectionResult = { success: !!process.env.DATABASE_URL, message: process.env.DATABASE_URL ? "PostgreSQL connection is configured" : "PostgreSQL connection not found" };
          break;
          
        default:
          return res.status(400).json({ message: "Unknown provider" });
      }
      
      res.json(connectionResult);
    } catch (error) {
      console.error("Error testing connection:", error);
      res.status(500).json({ message: "Failed to test connection" });
    }
  });

  // Data Source Configuration API endpoints
  app.get('/api/data-sources', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const dataSources = await storage.getDataSources(userId);
      res.json(dataSources);
    } catch (error) {
      console.error("Error fetching data sources:", error);
      res.status(500).json({ message: "Failed to fetch data sources" });
    }
  });

  app.get('/api/data-source-types', isAuthenticated, async (req: any, res) => {
    try {
      const types = await storage.getDataSourceTypes();
      res.json(types);
    } catch (error) {
      console.error("Error fetching data source types:", error);
      res.status(500).json({ message: "Failed to fetch data source types" });
    }
  });

  app.get('/api/database-types', isAuthenticated, async (req: any, res) => {
    try {
      const types = await storage.getDatabaseTypes();
      res.json(types);
    } catch (error) {
      console.error("Error fetching database types:", error);
      res.status(500).json({ message: "Failed to fetch database types" });
    }
  });

  app.post('/api/data-sources', isAuthenticated, async (req: any, res) => {
    try {
      const userId = req.user.claims.sub;
      const dataSourceData = {
        ...req.body,
        userId,
      };
      
      const dataSource = await storage.createDataSource(dataSourceData);
      
      // Log audit trail
      await storage.createAuditTrail({
        action: 'data_source_created',
        entityType: 'data_source',
        entityId: dataSource.id,
        userId,
        details: {
          name: dataSource.name,
          type: dataSource.type,
        },
      });

      res.json(dataSource);
    } catch (error) {
      console.error("Error creating data source:", error);
      res.status(500).json({ message: "Failed to create data source" });
    }
  });

  app.put('/api/data-sources/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const userId = req.user.claims.sub;
      const updates = req.body;
      
      const dataSource = await storage.updateDataSource(id, updates);
      
      // Log audit trail
      await storage.createAuditTrail({
        action: 'data_source_updated',
        entityType: 'data_source',
        entityId: id,
        userId,
        details: updates,
      });

      res.json(dataSource);
    } catch (error) {
      console.error("Error updating data source:", error);
      res.status(500).json({ message: "Failed to update data source" });
    }
  });

  app.delete('/api/data-sources/:id', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const userId = req.user.claims.sub;
      
      await storage.deleteDataSource(id);
      
      // Log audit trail
      await storage.createAuditTrail({
        action: 'data_source_deleted',
        entityType: 'data_source',
        entityId: id,
        userId,
        details: { deleted: true },
      });

      res.json({ message: "Data source deleted successfully" });
    } catch (error) {
      console.error("Error deleting data source:", error);
      res.status(500).json({ message: "Failed to delete data source" });
    }
  });

  app.post('/api/data-sources/:id/test', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      const userId = req.user.claims.sub;
      
      const result = await storage.testDataSourceConnection(id);
      
      // Log audit trail
      await storage.createAuditTrail({
        action: 'data_source_tested',
        entityType: 'data_source',
        entityId: id,
        userId,
        details: result,
      });

      res.json(result);
    } catch (error) {
      console.error("Error testing data source:", error);
      res.status(500).json({ message: "Failed to test data source connection" });
    }
  });

  app.get('/api/data-sources/:id/statistics', isAuthenticated, async (req: any, res) => {
    try {
      const { id } = req.params;
      
      // Mock statistics for now - in real implementation would query actual data
      const statistics = {
        totalRecords: Math.floor(Math.random() * 10000) + 1000,
        lastSync: new Date().toISOString(),
        avgResponseTime: Math.floor(Math.random() * 500) + 50,
        errorRate: Math.random() * 5,
        uptime: 99.5 + Math.random() * 0.5
      };

      res.json(statistics);
    } catch (error) {
      console.error("Error fetching data source statistics:", error);
      res.status(500).json({ message: "Failed to fetch statistics" });
    }
  });

  const httpServer = createServer(app);
  return httpServer;
}

// Helper functions for generating financial statements
async function generateTrialBalance(journalEntries: any[]): Promise<any> {
  const accountTotals = new Map();
  
  for (const entry of journalEntries) {
    const accountCode = entry.accountCode;
    const accountName = entry.accountName;
    const debitAmount = parseFloat(entry.debitAmount) || 0;
    const creditAmount = parseFloat(entry.creditAmount) || 0;
    
    if (!accountTotals.has(accountCode)) {
      accountTotals.set(accountCode, {
        accountCode,
        accountName,
        debitBalance: 0,
        creditBalance: 0
      });
    }
    
    const account = accountTotals.get(accountCode);
    account.debitBalance += debitAmount;
    account.creditBalance += creditAmount;
  }
  
  const entries = Array.from(accountTotals.values());
  const totalDebits = entries.reduce((sum, entry) => sum + entry.debitBalance, 0);
  const totalCredits = entries.reduce((sum, entry) => sum + entry.creditBalance, 0);
  
  return {
    entries,
    totalDebits,
    totalCredits,
    isBalanced: Math.abs(totalDebits - totalCredits) < 0.01
  };
}

async function generateProfitLoss(journalEntries: any[]): Promise<any> {
  const revenue = journalEntries.filter(entry => 
    entry.accountCode.startsWith('4') && parseFloat(entry.creditAmount) > 0
  );
  const expenses = journalEntries.filter(entry => 
    entry.accountCode.startsWith('5') && parseFloat(entry.debitAmount) > 0
  );
  
  const totalRevenue = revenue.reduce((sum, entry) => sum + parseFloat(entry.creditAmount), 0);
  const totalExpenses = expenses.reduce((sum, entry) => sum + parseFloat(entry.debitAmount), 0);
  
  return {
    revenue: revenue.map(entry => ({
      accountCode: entry.accountCode,
      accountName: entry.accountName,
      amount: parseFloat(entry.creditAmount),
      type: 'revenue'
    })),
    expenses: expenses.map(entry => ({
      accountCode: entry.accountCode,
      accountName: entry.accountName,
      amount: parseFloat(entry.debitAmount),
      type: 'expense'
    })),
    totalRevenue,
    totalExpenses,
    netProfit: totalRevenue - totalExpenses
  };
}

async function generateBalanceSheet(journalEntries: any[]): Promise<any> {
  const assets = journalEntries.filter(entry => 
    entry.accountCode.startsWith('1') && parseFloat(entry.debitAmount) > 0
  );
  const liabilities = journalEntries.filter(entry => 
    entry.accountCode.startsWith('2') && parseFloat(entry.creditAmount) > 0
  );
  
  const totalAssets = assets.reduce((sum, entry) => sum + parseFloat(entry.debitAmount), 0);
  const totalLiabilities = liabilities.reduce((sum, entry) => sum + parseFloat(entry.creditAmount), 0);
  
  return {
    assets: assets.map(entry => ({
      accountCode: entry.accountCode,
      accountName: entry.accountName,
      amount: parseFloat(entry.debitAmount),
      type: 'asset'
    })),
    liabilities: liabilities.map(entry => ({
      accountCode: entry.accountCode,
      accountName: entry.accountName,
      amount: parseFloat(entry.creditAmount),
      type: 'liability'
    })),
    totalAssets,
    totalLiabilities,
    totalEquity: totalAssets - totalLiabilities
  };
}
